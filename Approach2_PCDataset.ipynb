{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b5e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#For oversampling\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "#Train-test sets splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "#For DecisionTrees\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#For Logistic Regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#For Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#For Support Vector Machine\n",
    "from sklearn import svm\n",
    "#For Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a63a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\akram\\\\Desktop\\\\Dissertation\\\\Datasets\\\\PCDataset.csv\")\n",
    "\n",
    "features = df.drop(['InjuredNextTrainingSession'], axis = 1)\n",
    "target = df['InjuredNextTrainingSession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528a9eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3805, 1: 38})\n",
      "Counter({0: 3805, 1: 3800})\n"
     ]
    }
   ],
   "source": [
    "#Looking at proportion of '0's and '1's in the target column\n",
    "imbal_proportion = Counter(target)\n",
    "print(imbal_proportion)\n",
    "#Oversampling the training set\n",
    "oversample = ADASYN()\n",
    "featuresi, targeti = oversample.fit_resample(features, target)\n",
    "#Looking at new proportion of '0's and '1's\n",
    "bal_proportion = Counter(targeti)\n",
    "print(bal_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8312b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return accuracy metrics\n",
    "def accuraciz(y_test, y_pred):\n",
    "    count = Counter(y_test)\n",
    "    real_values_zero = count[0]\n",
    "    real_values_one = count[1]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    #Transform the data into a numerical vector\n",
    "    y_test = list(map(int, y_test))\n",
    "    y_pred = list(map(int, y_pred))\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == 1 and y_pred[i] == 1:\n",
    "            TP += 1\n",
    "        if y_pred[i] == 1 and y_test[i] != y_pred[i]:\n",
    "            FP += 1\n",
    "        if y_test[i] == y_pred[i] == 0:\n",
    "            TN += 1\n",
    "        if y_pred[i] == 0 and y_test[i] != y_pred[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    sensitivity = TP/(TP + FN)\n",
    "    specificity = TN/(FP + TN)\n",
    "    FPR = FP / real_values_zero\n",
    "    FNR = FN / real_values_one\n",
    "    acc = (TP + TN) / (real_values_one + real_values_zero)\n",
    "    ba = (sensitivity + specificity) / 2\n",
    "    f1 = (2*TP) / (2*TP + FP + FN)\n",
    "    LRplus = sensitivity/(1-specificity)\n",
    "    LRminus = (1-sensitivity)/specificity\n",
    "    \n",
    "    return sensitivity*100, specificity*100, FPR*100, FNR*100, acc*100, ba*100, f1*100, LRplus, LRminus, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a19535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 323390 (42.52333990795529%), FP: 78354 (10.302958579881658%)\n",
      "TN: 302146 (39.72991452991453%), FN: 56610 (7.443786982248521%)\n",
      "Sensitivity has mean 85.10263157894738 with variance 1.987001385041553\n",
      "Specificity has mean 79.40762155059132 with variance 1.1657587274507417\n",
      "False Positive Rate has mean 20.59237844940867 with variance 1.1657587274507397\n",
      "False Negative Rate has mean 14.897368421052626 with variance 1.987001385041551\n",
      "ACC has mean 82.25325443786984 with variance 0.6310202680768606\n",
      "Balanced Accuracy has mean 82.25512656476934 with variance 0.6312898275559518\n",
      "F1-Score has mean 82.73204263989018 with variance 0.6899453209123828\n",
      "Likelihood ratio positive has mean 4.143256918508445 with variance 0.04508040199247661\n",
      "Likelihood ratio negative has mean 0.1875911479324598 with variance 0.0003025726501615324\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Decision Tree classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myDT = DecisionTreeClassifier(criterion = 'gini', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myDT = cross_val_predict(myDT, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myDT)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bddc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 321475 (42.2715318869165%), FP: 85568 (11.25154503616042%)\n",
      "TN: 294932 (38.78132807363576%), FN: 58525 (7.695595003287311%)\n",
      "Sensitivity has mean 84.59868421052633 with variance 2.8329691828254857\n",
      "Specificity has mean 77.51169513797635 with variance 1.7159229936403608\n",
      "False Positive Rate has mean 22.48830486202365 with variance 1.7159229936403626\n",
      "False Negative Rate has mean 15.401315789473683 with variance 2.8329691828254857\n",
      "ACC has mean 81.05285996055225 with variance 0.8984063306563708\n",
      "Balanced Accuracy has mean 81.05518967425134 with variance 0.8987729438328994\n",
      "F1-Score has mean 81.68685304172215 with variance 0.9867452385165117\n",
      "Likelihood ratio positive has mean 3.7733955285949237 with variance 0.044742923678186816\n",
      "Likelihood ratio negative has mean 0.19867320607144257 with variance 0.00045183374311697714\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Decision Tree classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myDT = DecisionTreeClassifier(criterion = 'entropy', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myDT = cross_val_predict(myDT, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myDT)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a60a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 227989 (29.978829717291255%), FP: 194212 (25.53740959894806%)\n",
      "TN: 186288 (24.495463510848126%), FN: 152011 (19.988297172912556%)\n",
      "Sensitivity has mean 59.99710526315789 with variance 8.273779709141275\n",
      "Specificity has mean 48.95873850197109 with variance 0.675537996377268\n",
      "False Positive Rate has mean 51.041261498028916 with variance 0.675537996377268\n",
      "False Negative Rate has mean 40.0028947368421 with variance 8.273779709141275\n",
      "ACC has mean 54.47429322813939 with variance 2.0488782035072415\n",
      "Balanced Accuracy has mean 54.47792188256449 with variance 2.0513749343677397\n",
      "F1-Score has mean 56.814183022150594 with variance 3.7888716496013344\n",
      "Likelihood ratio positive has mean 1.1756288060345708 with variance 0.003214025772929973\n",
      "Likelihood ratio negative has mean 0.8171460459459309 with variance 0.0033802189994064113\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Logistic Regression classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myCLR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myCLR = cross_val_predict(myCLR, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myCLR)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a08ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 300191 (39.47284681130835%), FP: 254352 (33.445364891518736%)\n",
      "TN: 126148 (16.58750821827745%), FN: 79809 (10.494280078895464%)\n",
      "Sensitivity has mean 78.99763157894738 with variance 0.09440574792243783\n",
      "Specificity has mean 33.15321944809462 with variance 0.07558323735454275\n",
      "False Positive Rate has mean 66.8467805519054 with variance 0.07558323735454238\n",
      "False Negative Rate has mean 21.00236842105263 with variance 0.09440574792243779\n",
      "ACC has mean 56.06035502958581 with variance 0.05517631960356919\n",
      "Balanced Accuracy has mean 56.07542551352098 with variance 0.05518249426170316\n",
      "F1-Score has mean 64.2432775106793 with variance 0.04127793785369938\n",
      "Likelihood ratio positive has mean 1.181797407443566 with variance 5.840477681024392e-05\n",
      "Likelihood ratio negative has mean 0.6335603739027834 with variance 0.00014195441890526184\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Naive-Bayes classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myNB = GaussianNB()\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myNB = cross_val_predict(myNB, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myNB)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509dbc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 300665 (39.53517422748192%), FP: 240609 (31.63826429980276%)\n",
      "TN: 139891 (18.394608809993425%), FN: 79335 (10.431952662721894%)\n",
      "Sensitivity has mean 79.12236842105263 with variance 0.37163954293628754\n",
      "Specificity has mean 36.76504599211563 with variance 0.08382490015040028\n",
      "False Positive Rate has mean 63.23495400788438 with variance 0.08382490015040003\n",
      "False Negative Rate has mean 20.877631578947366 with variance 0.3716395429362885\n",
      "ACC has mean 57.929783037475346 with variance 0.10299573665375551\n",
      "Balanced Accuracy has mean 57.94370720658414 with variance 0.10309029640000056\n",
      "F1-Score has mean 65.2707844376775 with variance 0.11463178416146338\n",
      "Likelihood ratio positive has mean 1.2512649928762165 with variance 0.00011227337018395879\n",
      "Likelihood ratio negative has mean 0.5678857396231922 with variance 0.0002765369620699598\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Support Vector classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "mySVC = svm.SVC()\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_mySVC = cross_val_predict(mySVC, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_mySVC)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad4ebab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 333415 (43.84155161078238%), FP: 56774 (7.4653517422748195%)\n",
      "TN: 323726 (42.567521367521366%), FN: 46585 (6.125575279421433%)\n",
      "Sensitivity has mean 87.74078947368417 with variance 0.48380020775623195\n",
      "Specificity has mean 85.07910643889619 with variance 0.20998195541173598\n",
      "False Positive Rate has mean 14.920893561103812 with variance 0.20998195541173603\n",
      "False Negative Rate has mean 12.25921052631579 with variance 0.4838002077562327\n",
      "ACC has mean 86.40907297830375 with variance 0.16017731163232576\n",
      "Balanced Accuracy has mean 86.4099479562902 with variance 0.16026724353768682\n",
      "F1-Score has mean 86.5791356702072 with variance 0.17761998434758572\n",
      "Likelihood ratio positive has mean 5.885791297733118 with variance 0.032909809408294535\n",
      "Likelihood ratio negative has mean 0.14409251990110505 with variance 6.640156651416974e-05\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Support Vector classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myRF = RandomForestClassifier(criterion = 'entropy', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myRF = cross_val_predict(myRF, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myRF)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e52c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
