{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0a0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#For oversampling\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "#Train-test sets splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "#For DecisionTrees\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#For Logistic Regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#For Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#For Support Vector Machine\n",
    "from sklearn import svm\n",
    "#For Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51815571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\akram\\\\Desktop\\\\Dissertation\\\\Datasets\\\\PCDataset.csv\")\n",
    "\n",
    "features = df.drop(['InjuredNextTrainingSession'], axis = 1)\n",
    "target = df['InjuredNextTrainingSession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ab784ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2661, 1: 29})\n",
      "Counter({1: 2668, 0: 2661})\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into 70% training set, 30% test set; random state of 1 ensures\n",
    "#same distribution every time\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 1)\n",
    "#Looking at proportion of '0's and '1's in the target column\n",
    "imbal_proportion = Counter(y_train)\n",
    "print(imbal_proportion)\n",
    "#Oversampling the training set\n",
    "oversample = ADASYN()\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "#Looking at new proportion of '0's and '1's\n",
    "bal_proportion = Counter(y_train)\n",
    "print(bal_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6b6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return accuracy metrics\n",
    "def accuraciz(y_test, y_pred):\n",
    "    count = Counter(y_test)\n",
    "    real_values_zero = count[0]\n",
    "    real_values_one = count[1]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    #Transform the data into a numerical vector\n",
    "    y_test = list(map(int, y_test))\n",
    "    y_pred = list(map(int, y_pred))\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == 1 and y_pred[i] == 1:\n",
    "            TP += 1\n",
    "        if y_pred[i] == 1 and y_test[i] != y_pred[i]:\n",
    "            FP += 1\n",
    "        if y_test[i] == y_pred[i] == 0:\n",
    "            TN += 1\n",
    "        if y_pred[i] == 0 and y_test[i] != y_pred[i]:\n",
    "            FN += 1\n",
    "    \n",
    "    sensitivity = TP/(TP + FN)\n",
    "    specificity = TN/(FP + TN)\n",
    "    FPR = FP / real_values_zero\n",
    "    FNR = FN / real_values_one\n",
    "    acc = (TP + TN) / (real_values_one + real_values_zero)\n",
    "    ba = (sensitivity + specificity) / 2\n",
    "    f1 = (2*TP) / (2*TP + FP + FN)\n",
    "    LRplus = sensitivity/(1-specificity)\n",
    "    LRminus = (1-sensitivity)/specificity\n",
    "    \n",
    "    return sensitivity*100, specificity*100, FPR*100, FNR*100, acc*100, ba*100, f1*100, LRplus, LRminus, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c41148f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 322324 (42.38316896778435%), FP: 78834 (10.366074950690335%)\n",
      "TN: 301666 (39.66679815910585%), FN: 57676 (7.583957922419461%)\n",
      "Sensitivity has mean 84.82210526315787 with variance 1.653935180055402\n",
      "Specificity has mean 79.2814717477004 with variance 0.8156115215991142\n",
      "False Positive Rate has mean 20.718528252299606 with variance 0.8156115215991128\n",
      "False Negative Rate has mean 15.177894736842106 with variance 1.6539351800554019\n",
      "ACC has mean 82.04996712689021 with variance 0.6822235795077547\n",
      "Balanced Accuracy has mean 82.05178850542916 with variance 0.6824989238402156\n",
      "F1-Score has mean 82.52176233657954 with variance 0.7363162326447827\n",
      "Likelihood ratio positive has mean 4.102182727761354 with variance 0.03891381917665675\n",
      "Likelihood ratio negative has mean 0.19148862877208053 with variance 0.0002777822943218712\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Decision Tree classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myDT = DecisionTreeClassifier(criterion = 'gini', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myDT = cross_val_predict(myDT, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myDT)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "937ebcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 322253 (42.37383300460223%), FP: 85528 (11.246285338593031%)\n",
      "TN: 294972 (38.78658777120316%), FN: 57747 (7.593293885601578%)\n",
      "Sensitivity has mean 84.80342105263158 with variance 2.5810035318559583\n",
      "Specificity has mean 77.5222076215506 with variance 1.7801057810025904\n",
      "False Positive Rate has mean 22.477792378449408 with variance 1.7801057810025884\n",
      "False Negative Rate has mean 15.19657894736842 with variance 2.581003531855956\n",
      "ACC has mean 81.16042077580539 with variance 0.8868222703755987\n",
      "Balanced Accuracy has mean 81.16281433709109 with variance 0.8870849912618727\n",
      "F1-Score has mean 81.80879385287088 with variance 0.9386740783761822\n",
      "Likelihood ratio positive has mean 3.7853050053987816 with variance 0.05068241592961184\n",
      "Likelihood ratio negative has mean 0.19601652153861518 with variance 0.0004166378982258184\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Decision Tree classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myDT = DecisionTreeClassifier(criterion = 'entropy', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myDT = cross_val_predict(myDT, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myDT)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fdd8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 228517 (30.048257725180804%), FP: 194479 (25.572518080210386%)\n",
      "TN: 186021 (24.4603550295858%), FN: 151483 (19.91886916502301%)\n",
      "Sensitivity has mean 60.13605263157895 with variance 6.661288850415514\n",
      "Specificity has mean 48.88856767411301 with variance 0.6474266345029807\n",
      "False Positive Rate has mean 51.11143232588699 with variance 0.6474266345029801\n",
      "False Negative Rate has mean 39.86394736842105 with variance 6.661288850415514\n",
      "ACC has mean 54.50861275476658 with variance 1.6715802304878296\n",
      "Balanced Accuracy has mean 54.51231015284598 with variance 1.6735563178026902\n",
      "F1-Score has mean 56.8949194347716 with variance 3.0147495364726513\n",
      "Likelihood ratio positive has mean 1.1767441499551787 with variance 0.0026036652170363488\n",
      "Likelihood ratio negative has mean 0.8154957284370871 with variance 0.0027782572850544467\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Logistic Regression classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myCLR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myCLR = cross_val_predict(myCLR, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myCLR)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0964f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 299916 (39.43668639053254%), FP: 254482 (33.46245890861275%)\n",
      "TN: 126018 (16.570414201183432%), FN: 80084 (10.530440499671268%)\n",
      "Sensitivity has mean 78.92526315789475 with variance 0.10872188365651021\n",
      "Specificity has mean 33.11905387647832 with variance 0.06491741794892619\n",
      "False Positive Rate has mean 66.88094612352168 with variance 0.06491741794892616\n",
      "False Negative Rate has mean 21.074736842105267 with variance 0.1087218836565097\n",
      "ACC has mean 56.00710059171597 with variance 0.06251543047780368\n",
      "Balanced Accuracy has mean 56.02215851718653 with variance 0.062529819868473\n",
      "F1-Score has mean 64.19435697372705 with variance 0.04865492068579222\n",
      "Likelihood ratio positive has mean 1.180111647725781 with variance 6.485853606586872e-05\n",
      "Likelihood ratio negative has mean 0.6364049719777156 with variance 0.0001668873439256709\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Naive-Bayes classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myNB = GaussianNB()\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myNB = cross_val_predict(myNB, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myNB)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3a56503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 300462 (39.508481262327415%), FP: 240515 (31.625904010519395%)\n",
      "TN: 139985 (18.406969099276793%), FN: 79538 (10.458645627876397%)\n",
      "Sensitivity has mean 79.06894736842105 with variance 0.47735152354570604\n",
      "Specificity has mean 36.78975032851511 with variance 0.06674080200856126\n",
      "False Positive Rate has mean 63.21024967148489 with variance 0.06674080200856145\n",
      "False Negative Rate has mean 20.93105263157895 with variance 0.47735152354570637\n",
      "ACC has mean 57.91545036160421 with variance 0.11368850124122483\n",
      "Balanced Accuracy has mean 57.929348848468074 with variance 0.11382341336173234\n",
      "F1-Score has mean 65.24745980428679 with variance 0.13948407307943397\n",
      "Likelihood ratio positive has mean 1.2508978581870003 with variance 0.00011804880721910943\n",
      "Likelihood ratio negative has mean 0.5689323284780458 with variance 0.0003301913349506424\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Support Vector classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "mySVC = svm.SVC()\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_mySVC = cross_val_predict(mySVC, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_mySVC)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8aefd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 333544 (43.85851413543721%), FP: 56655 (7.449704142011834%)\n",
      "TN: 323845 (42.58316896778435%), FN: 46456 (6.108612754766601%)\n",
      "Sensitivity has mean 87.77473684210527 with variance 0.5455307479224374\n",
      "Specificity has mean 85.11038107752957 with variance 0.22213492517107788\n",
      "False Positive Rate has mean 14.889618922470433 with variance 0.2221349251710782\n",
      "False Negative Rate has mean 12.225263157894737 with variance 0.5455307479224374\n",
      "ACC has mean 86.44168310322155 with variance 0.16745582013978377\n",
      "Balanced Accuracy has mean 86.44255895981743 with variance 0.1675620369192049\n",
      "F1-Score has mean 86.61135323208622 with variance 0.18797352276755447\n",
      "Likelihood ratio positive has mean 5.9007012121575295 with variance 0.03464679752898727\n",
      "Likelihood ratio negative has mean 0.14363774767588144 with variance 7.400136836044761e-05\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "#Building the Support Vector classifier\n",
    "#Recursive to obtain mean and variance of results\n",
    "#10-fold cross validation\n",
    "myRF = RandomForestClassifier(criterion = 'entropy', max_depth = 10)\n",
    "\n",
    "while i < 101:\n",
    "    features_kfold, target_kfold = oversample.fit_resample(features, target)\n",
    "    y_pred_myRF = cross_val_predict(myRF, features_kfold, target_kfold, cv=10)\n",
    "\n",
    "    performance = accuraciz(target_kfold, y_pred_myRF)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e883534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1914 (0.49804839968774395%), FP: 190823 (49.654696851418166%)\n",
      "TN: 189677 (49.35649232370544%), FN: 1886 (0.4907624251886547%)\n",
      "Sensitivity has mean 50.36842105263158 with variance 48.340720221606674\n",
      "Specificity has mean 49.849408672798944 with variance 0.642585642724059\n",
      "False Positive Rate has mean 50.150591327201056 with variance 0.6425856427240594\n",
      "False Negative Rate has mean 49.63157894736841 with variance 48.34072022160668\n",
      "ACC has mean 49.854540723393185 with variance 0.6447996021843302\n",
      "Balanced Accuracy has mean 50.10891486271527 with variance 12.504564968053769\n",
      "F1-Score has mean 1.948212684823741 with variance 0.07314726007286222\n",
      "Likelihood ratio positive has mean 1.0048036830124625 with variance 0.019842643101759195\n",
      "Likelihood ratio negative has mean 0.9960986982247273 with variance 0.020197975888147427\n"
     ]
    }
   ],
   "source": [
    "#Random Baseline\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "ACCs = []\n",
    "BAs = []\n",
    "F1s = []\n",
    "LRpluses = []\n",
    "LRminuses = []\n",
    "TPs = []\n",
    "FPs = []\n",
    "TNs = []\n",
    "FNs = []\n",
    "\n",
    "i = 1\n",
    "while (i < 101) :\n",
    "    #All zero vector\n",
    "    b2 = np.random.randint(2, size = len(target))\n",
    "\n",
    "    performance = accuraciz(target, b2)\n",
    "    sensitivities.append(performance[0])\n",
    "    specificities.append(performance[1])\n",
    "    FPRs.append(performance[2])\n",
    "    FNRs.append(performance[3])\n",
    "    ACCs.append(performance[4])\n",
    "    BAs.append(performance[5])\n",
    "    F1s.append(performance[6])\n",
    "    LRpluses.append(performance[7])\n",
    "    LRminuses.append(performance[8])\n",
    "    TPs.append(performance[9])\n",
    "    FPs.append(performance[10])\n",
    "    TNs.append(performance[11])\n",
    "    FNs.append(performance[12])\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "TPz = np.sum(TPs)\n",
    "FPz = np.sum(FPs)\n",
    "TNz = np.sum(TNs)\n",
    "FNz = np.sum(FNs)\n",
    "totz = TPz + FPz + TNz + FNz\n",
    "\n",
    "print(\"TP: \"+str(TPz)+\" (\"+str(TPz*100/totz)+\"%), FP: \"+str(FPz)+\" (\"+str(FPz*100/totz)+\"%)\")\n",
    "print(\"TN: \"+str(TNz)+\" (\"+str(TNz*100/totz)+\"%), FN: \"+str(FNz)+\" (\"+str(FNz*100/totz)+\"%)\")\n",
    "print(\"Sensitivity has mean \"+str(np.mean(sensitivities))+\" with variance \"+str(np.var(sensitivities)))\n",
    "print(\"Specificity has mean \"+str(np.mean(specificities))+\" with variance \"+str(np.var(specificities)))\n",
    "print(\"False Positive Rate has mean \"+str(np.mean(FPRs))+\" with variance \"+str(np.var(FPRs)))\n",
    "print(\"False Negative Rate has mean \"+str(np.mean(FNRs))+\" with variance \"+str(np.var(FNRs)))\n",
    "print(\"ACC has mean \"+str(np.mean(ACCs))+\" with variance \"+str(np.var(ACCs)))\n",
    "print(\"Balanced Accuracy has mean \"+str(np.mean(BAs))+\" with variance \"+str(np.var(BAs)))\n",
    "print(\"F1-Score has mean \"+str(np.mean(F1s))+\" with variance \"+str(np.var(F1s)))\n",
    "print(\"Likelihood ratio positive has mean \"+str(np.mean(LRpluses))+\" with variance \"+str(np.var(LRpluses)))\n",
    "print(\"Likelihood ratio negative has mean \"+str(np.mean(LRminuses))+\" with variance \"+str(np.var(LRminuses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cad311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
